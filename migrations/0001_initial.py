# -*- coding: utf-8 -*-
# Generated by Django 1.11.6 on 2017-11-09 06:12
from __future__ import unicode_literals

from django.db import migrations, models
import django.db.models.deletion
import select2.fields


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('rules', '0001_initial'),
        ('home', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='AppLayerType',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(max_length=100, unique=True)),
            ],
        ),
        migrations.CreateModel(
            name='ConfSuricata',
            fields=[
                ('probeconfiguration_ptr', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.CASCADE, parent_link=True, primary_key=True, serialize=False, to='home.ProbeConfiguration')),
                ('conf_rules_directory', models.CharField(default='/etc/suricata/rules', max_length=400)),
                ('conf_script_directory', models.CharField(default='/etc/suricata/lua', max_length=400)),
                ('conf_file', models.CharField(default='/etc/suricata/suricata.yaml', max_length=400)),
                ('conf_advanced', models.BooleanField(default=False)),
                ('conf_advanced_text', models.TextField(default='%YAML 1.1\n---\n\n# Suricata configuration file. In addition to the comments describing all\n# options in this file, full documentation can be found at:\n# https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Suricatayaml\n\n##\n## Step 1: inform Suricata about your network\n##\n\nvars:\n  # more specifc is better for alert accuracy and performance\n  address-groups:\n    HOME_NET: "[192.168.0.0/16,10.0.0.0/8,172.16.0.0/12]"\n    #HOME_NET: "[192.168.0.0/16]"\n    #HOME_NET: "[10.0.0.0/8]"\n    #HOME_NET: "[172.16.0.0/12]"\n    #HOME_NET: "any"\n\n    EXTERNAL_NET: "!$HOME_NET"\n    #EXTERNAL_NET: "any"\n\n    HTTP_SERVERS: "$HOME_NET"\n    SMTP_SERVERS: "$HOME_NET"\n    SQL_SERVERS: "$HOME_NET"\n    DNS_SERVERS: "$HOME_NET"\n    TELNET_SERVERS: "$HOME_NET"\n    AIM_SERVERS: "$EXTERNAL_NET"\n    DNP3_SERVER: "$HOME_NET"\n    DNP3_CLIENT: "$HOME_NET"\n    MODBUS_CLIENT: "$HOME_NET"\n    MODBUS_SERVER: "$HOME_NET"\n    ENIP_CLIENT: "$HOME_NET"\n    ENIP_SERVER: "$HOME_NET"\n\n  port-groups:\n    HTTP_PORTS: "80"\n    SHELLCODE_PORTS: "!80"\n    ORACLE_PORTS: 1521\n    SSH_PORTS: 22\n    DNP3_PORTS: 20000\n    MODBUS_PORTS: 502\n    FILE_DATA_PORTS: "[$HTTP_PORTS,110,143]"\n    FTP_PORTS: 21\n\n\n##\n## Step 2: select the rules to enable or disable\n##\n\ndefault-rule-path: /usr/local/etc/suricata/rules\nrule-files:\n - botcc.rules\n # - botcc.portgrouped.rules\n - ciarmy.rules\n - compromised.rules\n - drop.rules\n - dshield.rules\n# - emerging-activex.rules\n - emerging-attack_response.rules\n - emerging-chat.rules\n - emerging-current_events.rules\n - emerging-dns.rules\n - emerging-dos.rules\n - emerging-exploit.rules\n - emerging-ftp.rules\n# - emerging-games.rules\n# - emerging-icmp_info.rules\n# - emerging-icmp.rules\n - emerging-imap.rules\n# - emerging-inappropriate.rules\n# - emerging-info.rules\n - emerging-malware.rules\n - emerging-misc.rules\n - emerging-mobile_malware.rules\n - emerging-netbios.rules\n - emerging-p2p.rules\n - emerging-policy.rules\n - emerging-pop3.rules\n - emerging-rpc.rules\n# - emerging-scada.rules\n# - emerging-scada_special.rules\n - emerging-scan.rules\n# - emerging-shellcode.rules\n - emerging-smtp.rules\n - emerging-snmp.rules\n - emerging-sql.rules\n - emerging-telnet.rules\n - emerging-tftp.rules\n - emerging-trojan.rules\n - emerging-user_agents.rules\n - emerging-voip.rules\n - emerging-web_client.rules\n - emerging-web_server.rules\n# - emerging-web_specific_apps.rules\n - emerging-worm.rules\n - tor.rules\n# - decoder-events.rules # available in suricata sources under rules dir\n# - stream-events.rules  # available in suricata sources under rules dir\n - http-events.rules    # available in suricata sources under rules dir\n - smtp-events.rules    # available in suricata sources under rules dir\n - dns-events.rules     # available in suricata sources under rules dir\n - tls-events.rules     # available in suricata sources under rules dir\n# - modbus-events.rules  # available in suricata sources under rules dir\n# - app-layer-events.rules  # available in suricata sources under rules dir\n# - dnp3-events.rules       # available in suricata sources under rules dir\n# - ntp-events.rules       # available in suricata sources under rules dir\n\nclassification-file: /usr/local/etc/suricata/classification.config\nreference-config-file: /usr/local/etc/suricata/reference.config\n# threshold-file: /usr/local/etc/suricata/threshold.config\n\n\n##\n## Step 3: select outputs to enable\n##\n\n# The default logging directory.  Any log or output file will be\n# placed here if its not specified with a full path name. This can be\n# overridden with the -l command line parameter.\ndefault-log-dir: /usr/local/var/log/suricata/\n\n# global stats configuration\nstats:\n  enabled: yes\n  # The interval field (in seconds) controls at what interval\n  # the loggers are invoked.\n  interval: 8\n\n# Configure the type of alert (and other) logging you would like.\noutputs:\n  # a line based alerts log similar to Snort\'s fast.log\n  - fast:\n      enabled: yes\n      filename: fast.log\n      append: yes\n      #filetype: regular # \'regular\', \'unix_stream\' or \'unix_dgram\'\n\n  # Extensible Event Format (nicknamed EVE) event log in JSON format\n  - eve-log:\n      enabled: no\n      filetype: regular #regular|syslog|unix_dgram|unix_stream|redis\n      filename: eve.json\n      #prefix: "@cee: " # prefix to prepend to each log entry\n      # the following are valid when type: syslog above\n      #identity: "suricata"\n      #facility: local5\n      #level: Info ## possible levels: Emergency, Alert, Critical,\n                   ## Error, Warning, Notice, Info, Debug\n      #redis:\n      #  server: 127.0.0.1\n      #  port: 6379\n      #  async: true ## if redis replies are read asynchronously\n      #  mode: list ## possible values: list (default), channel\n      #  key: suricata ## key or channel to use (default to suricata)\n      # Redis pipelining set up. This will enable to only do a query every\n      # \'batch-size\' events. This should lower the latency induced by network\n      # connection at the cost of some memory. There is no flushing implemented\n      # so this setting as to be reserved to high traffic suricata.\n      #  pipelining:\n      #    enabled: yes ## set enable to yes to enable query pipelining\n      #    batch-size: 10 ## number of entry to keep in buffer\n      types:\n        - alert:\n            # payload: yes             # enable dumping payload in Base64\n            # payload-buffer-size: 4kb # max size of payload buffer to output in eve-log\n            # payload-printable: yes   # enable dumping payload in printable (lossy) format\n            # packet: yes              # enable dumping of packet (without stream segments)\n            # http-body: yes           # enable dumping of http body in Base64\n            # http-body-printable: yes # enable dumping of http body in printable format\n            metadata: yes              # add L7/applayer fields, flowbit and other vars to the alert\n\n            # Enable the logging of tagged packets for rules using the\n            # "tag" keyword.\n            tagged-packets: yes\n\n            # HTTP X-Forwarded-For support by adding an extra field or overwriting\n            # the source or destination IP address (depending on flow direction)\n            # with the one reported in the X-Forwarded-For HTTP header. This is\n            # helpful when reviewing alerts for traffic that is being reverse\n            # or forward proxied.\n            xff:\n              enabled: no\n              # Two operation modes are available, "extra-data" and "overwrite".\n              mode: extra-data\n              # Two proxy deployments are supported, "reverse" and "forward". In\n              # a "reverse" deployment the IP address used is the last one, in a\n              # "forward" deployment the first IP address is used.\n              deployment: reverse\n              # Header name where the actual IP address will be reported, if more\n              # than one IP address is present, the last IP address will be the\n              # one taken into consideration.\n              header: X-Forwarded-For\n        - http:\n            extended: yes     # enable this for extended logging information\n            # custom allows additional http fields to be included in eve-log\n            # the example below adds three additional fields when uncommented\n            #custom: [Accept-Encoding, Accept-Language, Authorization]\n        - dns:\n            # control logging of queries and answers\n            # default yes, no to disable\n            query: yes     # enable logging of DNS queries\n            answer: yes    # enable logging of DNS answers\n            # control which RR types are logged\n            # all enabled if custom not specified\n            #custom: [a, aaaa, cname, mx, ns, ptr, txt]\n        - tls:\n            extended: yes     # enable this for extended logging information\n            # output TLS transaction where the session is resumed using a\n            # session id\n            #session-resumption: no\n            # custom allows to control which tls fields that are included\n            # in eve-log\n            #custom: [subject, issuer, session_resumed, serial, fingerprint, sni, version, not_before, not_after, certificate, chain]\n        - files:\n            force-magic: no   # force logging magic on all logged files\n            # force logging of checksums, available hash functions are md5,\n            # sha1 and sha256\n            #force-hash: [md5]\n        #- drop:\n        #    alerts: yes      # log alerts that caused drops\n        #    flows: all       # start or all: \'start\' logs only a single drop\n        #                     # per flow direction. All logs each dropped pkt.\n        - smtp:\n            #extended: yes # enable this for extended logging information\n            # this includes: bcc, message-id, subject, x_mailer, user-agent\n            # custom fields logging from the list:\n            #  reply-to, bcc, message-id, subject, x-mailer, user-agent, received,\n            #  x-originating-ip, in-reply-to, references, importance, priority,\n            #  sensitivity, organization, content-md5, date\n            #custom: [received, x-mailer, x-originating-ip, relays, reply-to, bcc]\n            # output md5 of fields: body, subject\n            # for the body you need to set app-layer.protocols.smtp.mime.body-md5\n            # to yes\n            #md5: [body, subject]\n\n        #- dnp3\n        #- nfs\n        - ssh\n        - stats:\n            totals: yes       # stats for all threads merged together\n            threads: no       # per thread stats\n            deltas: no        # include delta values\n        # bi-directional flows\n        - flow\n        # uni-directional flows\n        #- netflow\n        # Vars log flowbits and other packet and flow vars\n        #- vars\n\n  # alert output for use with Barnyard2\n  - unified2-alert:\n      enabled: no\n      filename: unified2.alert\n\n      # File size limit.  Can be specified in kb, mb, gb.  Just a number\n      # is parsed as bytes.\n      #limit: 32mb\n\n      # By default unified2 log files have the file creation time (in\n      # unix epoch format) appended to the filename. Set this to yes to\n      # disable this behaviour.\n      #nostamp: no\n\n      # Sensor ID field of unified2 alerts.\n      #sensor-id: 0\n\n      # Include payload of packets related to alerts. Defaults to true, set to\n      # false if payload is not required.\n      #payload: yes\n\n      # HTTP X-Forwarded-For support by adding the unified2 extra header or\n      # overwriting the source or destination IP address (depending on flow\n      # direction) with the one reported in the X-Forwarded-For HTTP header.\n      # This is helpful when reviewing alerts for traffic that is being reverse\n      # or forward proxied.\n      xff:\n        enabled: no\n        # Two operation modes are available, "extra-data" and "overwrite". Note\n        # that in the "overwrite" mode, if the reported IP address in the HTTP\n        # X-Forwarded-For header is of a different version of the packet\n        # received, it will fall-back to "extra-data" mode.\n        mode: extra-data\n        # Two proxy deployments are supported, "reverse" and "forward". In\n        # a "reverse" deployment the IP address used is the last one, in a\n        # "forward" deployment the first IP address is used.\n        deployment: reverse\n        # Header name where the actual IP address will be reported, if more\n        # than one IP address is present, the last IP address will be the\n        # one taken into consideration.\n        header: X-Forwarded-For\n\n  # a line based log of HTTP requests (no alerts)\n  - http-log:\n      enabled: no\n      filename: http.log\n      append: yes\n      #extended: yes     # enable this for extended logging information\n      #custom: yes       # enabled the custom logging format (defined by customformat)\n      #customformat: "%{%D-%H:%M:%S}t.%z %{X-Forwarded-For}i %H %m %h %u %s %B %a:%p -> %A:%P"\n      #filetype: regular # \'regular\', \'unix_stream\' or \'unix_dgram\'\n\n  # a line based log of TLS handshake parameters (no alerts)\n  - tls-log:\n      enabled: no  # Log TLS connections.\n      filename: tls.log # File to store TLS logs.\n      append: yes\n      #extended: yes     # Log extended information like fingerprint\n      #custom: yes       # enabled the custom logging format (defined by customformat)\n      #customformat: "%{%D-%H:%M:%S}t.%z %a:%p -> %A:%P %v %n %d %D"\n      #filetype: regular # \'regular\', \'unix_stream\' or \'unix_dgram\'\n      # output TLS transaction where the session is resumed using a\n      # session id\n      #session-resumption: no\n\n  # output module to store certificates chain to disk\n  - tls-store:\n      enabled: no\n      #certs-log-dir: certs # directory to store the certificates files\n\n  # a line based log of DNS requests and/or replies (no alerts)\n  - dns-log:\n      enabled: no\n      filename: dns.log\n      append: yes\n      #filetype: regular # \'regular\', \'unix_stream\' or \'unix_dgram\'\n\n  # Packet log... log packets in pcap format. 3 modes of operation: "normal"\n  # "multi" and "sguil".\n  #\n  # In normal mode a pcap file "filename" is created in the default-log-dir,\n  # or are as specified by "dir".\n  # In multi mode, a file is created per thread. This will perform much\n  # better, but will create multiple files where \'normal\' would create one.\n  # In multi mode the filename takes a few special variables:\n  # - %n -- thread number\n  # - %i -- thread id\n  # - %t -- timestamp (secs or secs.usecs based on \'ts-format\'\n  # E.g. filename: pcap.%n.%t\n  #\n  # Note that it\'s possible to use directories, but the directories are not\n  # created by Suricata. E.g. filename: pcaps/%n/log.%s will log into the\n  # per thread directory.\n  #\n  # Also note that the limit and max-files settings are enforced per thread.\n  # So the size limit when using 8 threads with 1000mb files and 2000 files\n  # is: 8*1000*2000 ~ 16TiB.\n  #\n  # In Sguil mode "dir" indicates the base directory. In this base dir the\n  # pcaps are created in th directory structure Sguil expects:\n  #\n  # $sguil-base-dir/YYYY-MM-DD/$filename.<timestamp>\n  #\n  # By default all packets are logged except:\n  # - TCP streams beyond stream.reassembly.depth\n  # - encrypted streams after the key exchange\n  #\n  - pcap-log:\n      enabled: no\n      filename: log.pcap\n\n      # File size limit.  Can be specified in kb, mb, gb.  Just a number\n      # is parsed as bytes.\n      limit: 1000mb\n\n      # If set to a value will enable ring buffer mode. Will keep Maximum of "max-files" of size "limit"\n      max-files: 2000\n\n      mode: normal # normal, multi or sguil.\n\n      # Directory to place pcap files. If not provided the default log\n      # directory will be used. Required for "sguil" mode.\n      #dir: /nsm_data/\n\n      #ts-format: usec # sec or usec second format (default) is filename.sec usec is filename.sec.usec\n      use-stream-depth: no #If set to "yes" packets seen after reaching stream inspection depth are ignored. "no" logs all packets\n      honor-pass-rules: no # If set to "yes", flows in which a pass rule matched will stopped being logged.\n\n  # a full alerts log containing much information for signature writers\n  # or for investigating suspected false positives.\n  - alert-debug:\n      enabled: no\n      filename: alert-debug.log\n      append: yes\n      #filetype: regular # \'regular\', \'unix_stream\' or \'unix_dgram\'\n\n  # alert output to prelude (http://www.prelude-technologies.com/) only\n  # available if Suricata has been compiled with --enable-prelude\n  - alert-prelude:\n      enabled: no\n      profile: suricata\n      log-packet-content: no\n      log-packet-header: yes\n\n  # Stats.log contains data from various counters of the suricata engine.\n  - stats:\n      enabled: yes\n      filename: stats.log\n      totals: yes       # stats for all threads merged together\n      threads: no       # per thread stats\n      #null-values: yes  # print counters that have value 0\n\n  # a line based alerts log similar to fast.log into syslog\n  - syslog:\n      enabled: no\n      # reported identity to syslog. If ommited the program name (usually\n      # suricata) will be used.\n      #identity: "suricata"\n      facility: local5\n      #level: Info ## possible levels: Emergency, Alert, Critical,\n                   ## Error, Warning, Notice, Info, Debug\n\n  # a line based information for dropped packets in IPS mode\n  - drop:\n      enabled: no\n      filename: drop.log\n      append: yes\n      #filetype: regular # \'regular\', \'unix_stream\' or \'unix_dgram\'\n\n  # output module to store extracted files to disk\n  #\n  # The files are stored to the log-dir in a format "file.<id>" where <id> is\n  # an incrementing number starting at 1. For each file "file.<id>" a meta\n  # file "file.<id>.meta" is created.\n  #\n  # File extraction depends on a lot of things to be fully done:\n  # - file-store stream-depth. For optimal results, set this to 0 (unlimited)\n  # - http request / response body sizes. Again set to 0 for optimal results.\n  # - rules that contain the "filestore" keyword.\n  - file-store:\n      enabled: no       # set to yes to enable\n      log-dir: files    # directory to store the files\n      force-magic: no   # force logging magic on all stored files\n      # force logging of checksums, available hash functions are md5,\n      # sha1 and sha256\n      #force-hash: [md5]\n      force-filestore: no # force storing of all files\n      # override global stream-depth for sessions in which we want to\n      # perform file extraction. Set to 0 for unlimited.\n      #stream-depth: 0\n      #waldo: file.waldo # waldo file to store the file_id across runs\n      # uncomment to disable meta file writing\n      #write-meta: no\n      # uncomment the following variable to define how many files can\n      # remain open for filestore by Suricata. Default value is 0 which\n      # means files get closed after each write\n      #max-open-files: 1000\n\n  # output module to log files tracked in a easily parsable json format\n  - file-log:\n      enabled: no\n      filename: files-json.log\n      append: yes\n      #filetype: regular # \'regular\', \'unix_stream\' or \'unix_dgram\'\n\n      force-magic: no   # force logging magic on all logged files\n      # force logging of checksums, available hash functions are md5,\n      # sha1 and sha256\n      #force-hash: [md5]\n\n  # Log TCP data after stream normalization\n  # 2 types: file or dir. File logs into a single logfile. Dir creates\n  # 2 files per TCP session and stores the raw TCP data into them.\n  # Using \'both\' will enable both file and dir modes.\n  #\n  # Note: limited by stream.depth\n  - tcp-data:\n      enabled: no\n      type: file\n      filename: tcp-data.log\n\n  # Log HTTP body data after normalization, dechunking and unzipping.\n  # 2 types: file or dir. File logs into a single logfile. Dir creates\n  # 2 files per HTTP session and stores the normalized data into them.\n  # Using \'both\' will enable both file and dir modes.\n  #\n  # Note: limited by the body limit settings\n  - http-body-data:\n      enabled: no\n      type: file\n      filename: http-data.log\n\n  # Lua Output Support - execute lua script to generate alert and event\n  # output.\n  # Documented at:\n  # https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Lua_Output\n  - lua:\n      enabled: no\n      #scripts-dir: /etc/suricata/lua-output/\n      scripts:\n      #   - script1.lua\n\n# Logging configuration.  This is not about logging IDS alerts/events, but\n# output about what Suricata is doing, like startup messages, errors, etc.\nlogging:\n  # The default log level, can be overridden in an output section.\n  # Note that debug level logging will only be emitted if Suricata was\n  # compiled with the --enable-debug configure option.\n  #\n  # This value is overriden by the SC_LOG_LEVEL env var.\n  default-log-level: notice\n\n  # The default output format.  Optional parameter, should default to\n  # something reasonable if not provided.  Can be overriden in an\n  # output section.  You can leave this out to get the default.\n  #\n  # This value is overriden by the SC_LOG_FORMAT env var.\n  #default-log-format: "[%i] %t - (%f:%l) <%d> (%n) -- "\n\n  # A regex to filter output.  Can be overridden in an output section.\n  # Defaults to empty (no filter).\n  #\n  # This value is overriden by the SC_LOG_OP_FILTER env var.\n  default-output-filter:\n\n  # Define your logging outputs.  If none are defined, or they are all\n  # disabled you will get the default - console output.\n  outputs:\n  - console:\n      enabled: yes\n      # type: json\n  - file:\n      enabled: yes\n      level: info\n      filename: /usr/local/var/log/suricata/suricata.log\n      # type: json\n  - syslog:\n      enabled: no\n      facility: local5\n      format: "[%i] <%d> -- "\n      # type: json\n\n\n##\n## Step 4: configure common capture settings\n##\n## See "Advanced Capture Options" below for more options, including NETMAP\n## and PF_RING.\n##\n\n# Linux high speed capture support\naf-packet:\n  - interface: eth0\n    # Number of receive threads. "auto" uses the number of cores\n    #threads: auto\n    # Default clusterid. AF_PACKET will load balance packets based on flow.\n    cluster-id: 99\n    # Default AF_PACKET cluster type. AF_PACKET can load balance per flow or per hash.\n    # This is only supported for Linux kernel > 3.1\n    # possible value are:\n    #  * cluster_round_robin: round robin load balancing\n    #  * cluster_flow: all packets of a given flow are send to the same socket\n    #  * cluster_cpu: all packets treated in kernel by a CPU are send to the same socket\n    #  * cluster_qm: all packets linked by network card to a RSS queue are sent to the same\n    #  socket. Requires at least Linux 3.14.\n    #  * cluster_random: packets are sent randomly to sockets but with an equipartition.\n    #  Requires at least Linux 3.14.\n    #  * cluster_rollover: kernel rotates between sockets filling each socket before moving\n    #  to the next. Requires at least Linux 3.10.\n    # Recommended modes are cluster_flow on most boxes and cluster_cpu or cluster_qm on system\n    # with capture card using RSS (require cpu affinity tuning and system irq tuning)\n    cluster-type: cluster_flow\n    # In some fragmentation case, the hash can not be computed. If "defrag" is set\n    # to yes, the kernel will do the needed defragmentation before sending the packets.\n    defrag: yes\n    # After Linux kernel 3.10 it is possible to activate the rollover option: if a socket is\n    # full then kernel will send the packet on the next socket with room available. This option\n    # can minimize packet drop and increase the treated bandwidth on single intensive flow.\n    #rollover: yes\n    # To use the ring feature of AF_PACKET, set \'use-mmap\' to yes\n    #use-mmap: yes\n    # Lock memory map to avoid it goes to swap. Be careful that over suscribing could lock\n    # your system\n    #mmap-locked: yes\n    # Use tpacket_v3 capture mode, only active if use-mmap is true\n    # Don\'t use it in IPS or TAP mode as it causes severe latency\n    #tpacket-v3: yes\n    # Ring size will be computed with respect to max_pending_packets and number\n    # of threads. You can set manually the ring size in number of packets by setting\n    # the following value. If you are using flow cluster-type and have really network\n    # intensive single-flow you could want to set the ring-size independently of the number\n    # of threads:\n    #ring-size: 2048\n    # Block size is used by tpacket_v3 only. It should set to a value high enough to contain\n    # a decent number of packets. Size is in bytes so please consider your MTU. It should be\n    # a power of 2 and it must be multiple of page size (usually 4096).\n    #block-size: 32768\n    # tpacket_v3 block timeout: an open block is passed to userspace if it is not\n    # filled after block-timeout milliseconds.\n    #block-timeout: 10\n    # On busy system, this could help to set it to yes to recover from a packet drop\n    # phase. This will result in some packets (at max a ring flush) being non treated.\n    #use-emergency-flush: yes\n    # recv buffer size, increase value could improve performance\n    # buffer-size: 32768\n    # Set to yes to disable promiscuous mode\n    # disable-promisc: no\n    # Choose checksum verification mode for the interface. At the moment\n    # of the capture, some packets may be with an invalid checksum due to\n    # offloading to the network card of the checksum computation.\n    # Possible values are:\n    #  - kernel: use indication sent by kernel for each packet (default)\n    #  - yes: checksum validation is forced\n    #  - no: checksum validation is disabled\n    #  - auto: suricata uses a statistical approach to detect when\n    #  checksum off-loading is used.\n    # Warning: \'checksum-validation\' must be set to yes to have any validation\n    #checksum-checks: kernel\n    # BPF filter to apply to this interface. The pcap filter syntax apply here.\n    #bpf-filter: port 80 or udp\n    # You can use the following variables to activate AF_PACKET tap or IPS mode.\n    # If copy-mode is set to ips or tap, the traffic coming to the current\n    # interface will be copied to the copy-iface interface. If \'tap\' is set, the\n    # copy is complete. If \'ips\' is set, the packet matching a \'drop\' action\n    # will not be copied.\n    #copy-mode: ips\n    #copy-iface: eth1\n\n  # Put default values here. These will be used for an interface that is not\n  # in the list above.\n  - interface: default\n    #threads: auto\n    #use-mmap: no\n    #rollover: yes\n    #tpacket-v3: yes\n\n# Cross platform libpcap capture support\npcap:\n  - interface: eth0\n    # On Linux, pcap will try to use mmaped capture and will use buffer-size\n    # as total of memory used by the ring. So set this to something bigger\n    # than 1% of your bandwidth.\n    #buffer-size: 16777216\n    #bpf-filter: "tcp and port 25"\n    # Choose checksum verification mode for the interface. At the moment\n    # of the capture, some packets may be with an invalid checksum due to\n    # offloading to the network card of the checksum computation.\n    # Possible values are:\n    #  - yes: checksum validation is forced\n    #  - no: checksum validation is disabled\n    #  - auto: suricata uses a statistical approach to detect when\n    #  checksum off-loading is used. (default)\n    # Warning: \'checksum-validation\' must be set to yes to have any validation\n    #checksum-checks: auto\n    # With some accelerator cards using a modified libpcap (like myricom), you\n    # may want to have the same number of capture threads as the number of capture\n    # rings. In this case, set up the threads variable to N to start N threads\n    # listening on the same interface.\n    #threads: 16\n    # set to no to disable promiscuous mode:\n    #promisc: no\n    # set snaplen, if not set it defaults to MTU if MTU can be known\n    # via ioctl call and to full capture if not.\n    #snaplen: 1518\n  # Put default values here\n  - interface: default\n    #checksum-checks: auto\n\n# Settings for reading pcap files\npcap-file:\n  # Possible values are:\n  #  - yes: checksum validation is forced\n  #  - no: checksum validation is disabled\n  #  - auto: suricata uses a statistical approach to detect when\n  #  checksum off-loading is used. (default)\n  # Warning: \'checksum-validation\' must be set to yes to have checksum tested\n  checksum-checks: auto\n\n# See "Advanced Capture Options" below for more options, including NETMAP\n# and PF_RING.\n\n\n##\n## Step 5: App Layer Protocol Configuration\n##\n\n# Configure the app-layer parsers. The protocols section details each\n# protocol.\n#\n# The option "enabled" takes 3 values - "yes", "no", "detection-only".\n# "yes" enables both detection and the parser, "no" disables both, and\n# "detection-only" enables protocol detection only (parser disabled).\napp-layer:\n  protocols:\n    tls:\n      enabled: yes\n      detection-ports:\n        dp: 443\n\n      # Completely stop processing TLS/SSL session after the handshake\n      # completed. If bypass is enabled this will also trigger flow\n      # bypass. If disabled (the default), TLS/SSL session is still\n      # tracked for Heartbleed and other anomalies.\n      #no-reassemble: yes\n    dcerpc:\n      enabled: yes\n    ftp:\n      enabled: yes\n    ssh:\n      enabled: yes\n    smtp:\n      enabled: yes\n      # Configure SMTP-MIME Decoder\n      mime:\n        # Decode MIME messages from SMTP transactions\n        # (may be resource intensive)\n        # This field supercedes all others because it turns the entire\n        # process on or off\n        decode-mime: yes\n\n        # Decode MIME entity bodies (ie. base64, quoted-printable, etc.)\n        decode-base64: yes\n        decode-quoted-printable: yes\n\n        # Maximum bytes per header data value stored in the data structure\n        # (default is 2000)\n        header-value-depth: 2000\n\n        # Extract URLs and save in state data structure\n        extract-urls: yes\n        # Set to yes to compute the md5 of the mail body. You will then\n        # be able to journalize it.\n        body-md5: no\n      # Configure inspected-tracker for file_data keyword\n      inspected-tracker:\n        content-limit: 100000\n        content-inspect-min-size: 32768\n        content-inspect-window: 4096\n    imap:\n      enabled: detection-only\n    msn:\n      enabled: detection-only\n    smb:\n      enabled: yes\n      detection-ports:\n        dp: 139, 445\n    # smb2 detection is disabled internally inside the engine.\n    #smb2:\n    #  enabled: yes\n    # Note: NFS parser depends on Rust support: pass --enable-rust\n    # to configure.\n    nfs:\n      enabled: no\n    dns:\n      # memcaps. Globally and per flow/state.\n      #global-memcap: 16mb\n      #state-memcap: 512kb\n\n      # How many unreplied DNS requests are considered a flood.\n      # If the limit is reached, app-layer-event:dns.flooded; will match.\n      #request-flood: 500\n\n      tcp:\n        enabled: yes\n        detection-ports:\n          dp: 53\n      udp:\n        enabled: yes\n        detection-ports:\n          dp: 53\n    http:\n      enabled: yes\n      # memcap: 64mb\n\n      # default-config:           Used when no server-config matches\n      #   personality:            List of personalities used by default\n      #   request-body-limit:     Limit reassembly of request body for inspection\n      #                           by http_client_body & pcre /P option.\n      #   response-body-limit:    Limit reassembly of response body for inspection\n      #                           by file_data, http_server_body & pcre /Q option.\n      #   double-decode-path:     Double decode path section of the URI\n      #   double-decode-query:    Double decode query section of the URI\n      #   response-body-decompress-layer-limit:\n      #                           Limit to how many layers of compression will be\n      #                           decompressed. Defaults to 2.\n      #\n      # server-config:            List of server configurations to use if address matches\n      #   address:                List of ip addresses or networks for this block\n      #   personalitiy:           List of personalities used by this block\n      #   request-body-limit:     Limit reassembly of request body for inspection\n      #                           by http_client_body & pcre /P option.\n      #   response-body-limit:    Limit reassembly of response body for inspection\n      #                           by file_data, http_server_body & pcre /Q option.\n      #   double-decode-path:     Double decode path section of the URI\n      #   double-decode-query:    Double decode query section of the URI\n      #\n      #   uri-include-all:        Include all parts of the URI. By default the\n      #                           \'scheme\', username/password, hostname and port\n      #                           are excluded. Setting this option to true adds\n      #                           all of them to the normalized uri as inspected\n      #                           by http_uri, urilen, pcre with /U and the other\n      #                           keywords that inspect the normalized uri.\n      #                           Note that this does not affect http_raw_uri.\n      #                           Also, note that including all was the default in\n      #                           1.4 and 2.0beta1.\n      #\n      #   meta-field-limit:       Hard size limit for request and response size\n      #                           limits. Applies to request line and headers,\n      #                           response line and headers. Does not apply to\n      #                           request or response bodies. Default is 18k.\n      #                           If this limit is reached an event is raised.\n      #\n      # Currently Available Personalities:\n      #   Minimal, Generic, IDS (default), IIS_4_0, IIS_5_0, IIS_5_1, IIS_6_0,\n      #   IIS_7_0, IIS_7_5, Apache_2\n      libhtp:\n         default-config:\n           personality: IDS\n\n           # Can be specified in kb, mb, gb.  Just a number indicates\n           # it\'s in bytes.\n           request-body-limit: 100kb\n           response-body-limit: 100kb\n\n           # inspection limits\n           request-body-minimal-inspect-size: 32kb\n           request-body-inspect-window: 4kb\n           response-body-minimal-inspect-size: 40kb\n           response-body-inspect-window: 16kb\n\n           # response body decompression (0 disables)\n           response-body-decompress-layer-limit: 2\n\n           # auto will use http-body-inline mode in IPS mode, yes or no set it statically\n           http-body-inline: auto\n\n           # Take a random value for inspection sizes around the specified value.\n           # This lower the risk of some evasion technics but could lead\n           # detection change between runs. It is set to \'yes\' by default.\n           #randomize-inspection-sizes: yes\n           # If randomize-inspection-sizes is active, the value of various\n           # inspection size will be choosen in the [1 - range%, 1 + range%]\n           # range\n           # Default value of randomize-inspection-range is 10.\n           #randomize-inspection-range: 10\n\n           # decoding\n           double-decode-path: no\n           double-decode-query: no\n\n         server-config:\n\n           #- apache:\n           #    address: [192.168.1.0/24, 127.0.0.0/8, "::1"]\n           #    personality: Apache_2\n           #    # Can be specified in kb, mb, gb.  Just a number indicates\n           #    # it\'s in bytes.\n           #    request-body-limit: 4096\n           #    response-body-limit: 4096\n           #    double-decode-path: no\n           #    double-decode-query: no\n\n           #- iis7:\n           #    address:\n           #      - 192.168.0.0/24\n           #      - 192.168.10.0/24\n           #    personality: IIS_7_0\n           #    # Can be specified in kb, mb, gb.  Just a number indicates\n           #    # it\'s in bytes.\n           #    request-body-limit: 4096\n           #    response-body-limit: 4096\n           #    double-decode-path: no\n           #    double-decode-query: no\n\n    # Note: Modbus probe parser is minimalist due to the poor significant field\n    # Only Modbus message length (greater than Modbus header length)\n    # And Protocol ID (equal to 0) are checked in probing parser\n    # It is important to enable detection port and define Modbus port\n    # to avoid false positive\n    modbus:\n      # How many unreplied Modbus requests are considered a flood.\n      # If the limit is reached, app-layer-event:modbus.flooded; will match.\n      #request-flood: 500\n\n      enabled: no\n      detection-ports:\n        dp: 502\n      # According to MODBUS Messaging on TCP/IP Implementation Guide V1.0b, it\n      # is recommended to keep the TCP connection opened with a remote device\n      # and not to open and close it for each MODBUS/TCP transaction. In that\n      # case, it is important to set the depth of the stream reassembling as\n      # unlimited (stream.reassembly.depth: 0)\n\n      # Stream reassembly size for modbus. By default track it completely.\n      stream-depth: 0\n\n    # DNP3\n    dnp3:\n      enabled: no\n      detection-ports:\n        dp: 20000\n\n    # SCADA EtherNet/IP and CIP protocol support\n    enip:\n      enabled: no\n      detection-ports:\n        dp: 44818\n        sp: 44818\n\n    # Note: parser depends on experimental Rust support\n    # with --enable-rust-experimental passed to configure\n    ntp:\n      enabled: no\n\n# Limit for the maximum number of asn1 frames to decode (default 256)\nasn1-max-frames: 256\n\n\n##############################################################################\n##\n## Advanced settings below\n##\n##############################################################################\n\n##\n## Run Options\n##\n\n# Run suricata as user and group.\n#run-as:\n#  user: suri\n#  group: suri\n\n# Some logging module will use that name in event as identifier. The default\n# value is the hostname\n#sensor-name: suricata\n\n# Default location of the pid file. The pid file is only used in\n# daemon mode (start Suricata with -D). If not running in daemon mode\n# the --pidfile command line option must be used to create a pid file.\n#pid-file: /usr/local/var/run/suricata.pid\n\n# Daemon working directory\n# Suricata will change directory to this one if provided\n# Default: "/"\n#daemon-directory: "/"\n\n# Suricata core dump configuration. Limits the size of the core dump file to\n# approximately max-dump. The actual core dump size will be a multiple of the\n# page size. Core dumps that would be larger than max-dump are truncated. On\n# Linux, the actual core dump size may be a few pages larger than max-dump.\n# Setting max-dump to 0 disables core dumping.\n# Setting max-dump to \'unlimited\' will give the full core dump file.\n# On 32-bit Linux, a max-dump value >= ULONG_MAX may cause the core dump size\n# to be \'unlimited\'.\n\ncoredump:\n  max-dump: unlimited\n\n# If suricata box is a router for the sniffed networks, set it to \'router\'. If\n# it is a pure sniffing setup, set it to \'sniffer-only\'.\n# If set to auto, the variable is internally switch to \'router\' in IPS mode\n# and \'sniffer-only\' in IDS mode.\n# This feature is currently only used by the reject* keywords.\nhost-mode: auto\n\n# Number of packets preallocated per thread. The default is 1024. A higher number\n# will make sure each CPU will be more easily kept busy, but may negatively\n# impact caching.\n#\n# If you are using the CUDA pattern matcher (mpm-algo: ac-cuda), different rules\n# apply. In that case try something like 60000 or more. This is because the CUDA\n# pattern matcher buffers and scans as many packets as possible in parallel.\n#max-pending-packets: 1024\n\n# Runmode the engine should use. Please check --list-runmodes to get the available\n# runmodes for each packet acquisition method. Defaults to "autofp" (auto flow pinned\n# load balancing).\n#runmode: autofp\n\n# Specifies the kind of flow load balancer used by the flow pinned autofp mode.\n#\n# Supported schedulers are:\n#\n# round-robin       - Flows assigned to threads in a round robin fashion.\n# active-packets    - Flows assigned to threads that have the lowest number of\n#                     unprocessed packets (default).\n# hash              - Flow alloted usihng the address hash. More of a random\n#                     technique. Was the default in Suricata 1.2.1 and older.\n#\n#autofp-scheduler: active-packets\n\n# Preallocated size for packet. Default is 1514 which is the classical\n# size for pcap on ethernet. You should adjust this value to the highest\n# packet size (MTU + hardware header) on your system.\n#default-packet-size: 1514\n\n# Unix command socket can be used to pass commands to suricata.\n# An external tool can then connect to get information from suricata\n# or trigger some modifications of the engine. Set enabled to yes\n# to activate the feature. In auto mode, the feature will only be\n# activated in live capture mode. You can use the filename variable to set\n# the file name of the socket.\nunix-command:\n  enabled: auto\n  #filename: custom.socket\n\n# Magic file. The extension .mgc is added to the value here.\n#magic-file: /usr/local/opt/libmagic/share/misc/magic\n#magic-file:\n\nlegacy:\n  uricontent: enabled\n\n##\n## Detection settings\n##\n\n# Set the order of alerts bassed on actions\n# The default order is pass, drop, reject, alert\n# action-order:\n#   - pass\n#   - drop\n#   - reject\n#   - alert\n\n# IP Reputation\n#reputation-categories-file: /usr/local/etc/suricata/iprep/categories.txt\n#default-reputation-path: /usr/local/etc/suricata/iprep\n#reputation-files:\n# - reputation.list\n\n# When run with the option --engine-analysis, the engine will read each of\n# the parameters below, and print reports for each of the enabled sections\n# and exit.  The reports are printed to a file in the default log dir\n# given by the parameter "default-log-dir", with engine reporting\n# subsection below printing reports in its own report file.\nengine-analysis:\n  # enables printing reports for fast-pattern for every rule.\n  rules-fast-pattern: yes\n  # enables printing reports for each rule\n  rules: yes\n\n#recursion and match limits for PCRE where supported\npcre:\n  match-limit: 3500\n  match-limit-recursion: 1500\n\n##\n## Advanced Traffic Tracking and Reconstruction Settings\n##\n\n# Host specific policies for defragmentation and TCP stream\n# reassembly. The host OS lookup is done using a radix tree, just\n# like a routing table so the most specific entry matches.\nhost-os-policy:\n  # Make the default policy windows.\n  windows: [0.0.0.0/0]\n  bsd: []\n  bsd-right: []\n  old-linux: []\n  linux: []\n  old-solaris: []\n  solaris: []\n  hpux10: []\n  hpux11: []\n  irix: []\n  macos: []\n  vista: []\n  windows2k3: []\n\n# Defrag settings:\n\ndefrag:\n  memcap: 32mb\n  hash-size: 65536\n  trackers: 65535 # number of defragmented flows to follow\n  max-frags: 65535 # number of fragments to keep (higher than trackers)\n  prealloc: yes\n  timeout: 60\n\n# Enable defrag per host settings\n#  host-config:\n#\n#    - dmz:\n#        timeout: 30\n#        address: [192.168.1.0/24, 127.0.0.0/8, 1.1.1.0/24, 2.2.2.0/24, "1.1.1.1", "2.2.2.2", "::1"]\n#\n#    - lan:\n#        timeout: 45\n#        address:\n#          - 192.168.0.0/24\n#          - 192.168.10.0/24\n#          - 172.16.14.0/24\n\n# Flow settings:\n# By default, the reserved memory (memcap) for flows is 32MB. This is the limit\n# for flow allocation inside the engine. You can change this value to allow\n# more memory usage for flows.\n# The hash-size determine the size of the hash used to identify flows inside\n# the engine, and by default the value is 65536.\n# At the startup, the engine can preallocate a number of flows, to get a better\n# performance. The number of flows preallocated is 10000 by default.\n# emergency-recovery is the percentage of flows that the engine need to\n# prune before unsetting the emergency state. The emergency state is activated\n# when the memcap limit is reached, allowing to create new flows, but\n# prunning them with the emergency timeouts (they are defined below).\n# If the memcap is reached, the engine will try to prune flows\n# with the default timeouts. If it doens\'t find a flow to prune, it will set\n# the emergency bit and it will try again with more agressive timeouts.\n# If that doesn\'t work, then it will try to kill the last time seen flows\n# not in use.\n# The memcap can be specified in kb, mb, gb.  Just a number indicates it\'s\n# in bytes.\n\nflow:\n  memcap: 128mb\n  hash-size: 65536\n  prealloc: 10000\n  emergency-recovery: 30\n  #managers: 1 # default to one flow manager\n  #recyclers: 1 # default to one flow recycler thread\n\n# This option controls the use of vlan ids in the flow (and defrag)\n# hashing. Normally this should be enabled, but in some (broken)\n# setups where both sides of a flow are not tagged with the same vlan\n# tag, we can ignore the vlan id\'s in the flow hashing.\nvlan:\n  use-for-tracking: true\n\n# Specific timeouts for flows. Here you can specify the timeouts that the\n# active flows will wait to transit from the current state to another, on each\n# protocol. The value of "new" determine the seconds to wait after a hanshake or\n# stream startup before the engine free the data of that flow it doesn\'t\n# change the state to established (usually if we don\'t receive more packets\n# of that flow). The value of "established" is the amount of\n# seconds that the engine will wait to free the flow if it spend that amount\n# without receiving new packets or closing the connection. "closed" is the\n# amount of time to wait after a flow is closed (usually zero). "bypassed"\n# timeout controls locally bypassed flows. For these flows we don\'t do any other\n# tracking. If no packets have been seen after this timeout, the flow is discarded.\n#\n# There\'s an emergency mode that will become active under attack circumstances,\n# making the engine to check flow status faster. This configuration variables\n# use the prefix "emergency-" and work similar as the normal ones.\n# Some timeouts doesn\'t apply to all the protocols, like "closed", for udp and\n# icmp.\n\nflow-timeouts:\n\n  default:\n    new: 30\n    established: 300\n    closed: 0\n    bypassed: 100\n    emergency-new: 10\n    emergency-established: 100\n    emergency-closed: 0\n    emergency-bypassed: 50\n  tcp:\n    new: 60\n    established: 600\n    closed: 60\n    bypassed: 100\n    emergency-new: 5\n    emergency-established: 100\n    emergency-closed: 10\n    emergency-bypassed: 50\n  udp:\n    new: 30\n    established: 300\n    bypassed: 100\n    emergency-new: 10\n    emergency-established: 100\n    emergency-bypassed: 50\n  icmp:\n    new: 30\n    established: 300\n    bypassed: 100\n    emergency-new: 10\n    emergency-established: 100\n    emergency-bypassed: 50\n\n# Stream engine settings. Here the TCP stream tracking and reassembly\n# engine is configured.\n#\n# stream:\n#   memcap: 32mb                # Can be specified in kb, mb, gb.  Just a\n#                               # number indicates it\'s in bytes.\n#   checksum-validation: yes    # To validate the checksum of received\n#                               # packet. If csum validation is specified as\n#                               # "yes", then packet with invalid csum will not\n#                               # be processed by the engine stream/app layer.\n#                               # Warning: locally generated trafic can be\n#                               # generated without checksum due to hardware offload\n#                               # of checksum. You can control the handling of checksum\n#                               # on a per-interface basis via the \'checksum-checks\'\n#                               # option\n#   prealloc-sessions: 2k       # 2k sessions prealloc\'d per stream thread\n#   midstream: false            # don\'t allow midstream session pickups\n#   async-oneside: false        # don\'t enable async stream handling\n#   inline: no                  # stream inline mode\n#   drop-invalid: yes           # in inline mode, drop packets that are invalid with regards to streaming engine\n#   max-synack-queued: 5        # Max different SYN/ACKs to queue\n#   bypass: no                  # Bypass packets when stream.depth is reached\n#\n#   reassembly:\n#     memcap: 64mb              # Can be specified in kb, mb, gb.  Just a number\n#                               # indicates it\'s in bytes.\n#     depth: 1mb                # Can be specified in kb, mb, gb.  Just a number\n#                               # indicates it\'s in bytes.\n#     toserver-chunk-size: 2560 # inspect raw stream in chunks of at least\n#                               # this size.  Can be specified in kb, mb,\n#                               # gb.  Just a number indicates it\'s in bytes.\n#     toclient-chunk-size: 2560 # inspect raw stream in chunks of at least\n#                               # this size.  Can be specified in kb, mb,\n#                               # gb.  Just a number indicates it\'s in bytes.\n#     randomize-chunk-size: yes # Take a random value for chunk size around the specified value.\n#                               # This lower the risk of some evasion technics but could lead\n#                               # detection change between runs. It is set to \'yes\' by default.\n#     randomize-chunk-range: 10 # If randomize-chunk-size is active, the value of chunk-size is\n#                               # a random value between (1 - randomize-chunk-range/100)*toserver-chunk-size\n#                               # and (1 + randomize-chunk-range/100)*toserver-chunk-size and the same\n#                               # calculation for toclient-chunk-size.\n#                               # Default value of randomize-chunk-range is 10.\n#\n#     raw: yes                  # \'Raw\' reassembly enabled or disabled.\n#                               # raw is for content inspection by detection\n#                               # engine.\n#\n#     segment-prealloc: 2048    # number of segments preallocated per thread\n#\n#     check-overlap-different-data: true|false\n#                               # check if a segment contains different data\n#                               # than what we\'ve already seen for that\n#                               # position in the stream.\n#                               # This is enabled automatically if inline mode\n#                               # is used or when stream-event:reassembly_overlap_different_data;\n#                               # is used in a rule.\n#\nstream:\n  memcap: 64mb\n  checksum-validation: yes      # reject wrong csums\n  inline: auto                  # auto will use inline mode in IPS mode, yes or no set it statically\n  reassembly:\n    memcap: 256mb\n    depth: 1mb                  # reassemble 1mb into a stream\n    toserver-chunk-size: 2560\n    toclient-chunk-size: 2560\n    randomize-chunk-size: yes\n    #randomize-chunk-range: 10\n    #raw: yes\n    #segment-prealloc: 2048\n    #check-overlap-different-data: true\n\n# Host table:\n#\n# Host table is used by tagging and per host thresholding subsystems.\n#\nhost:\n  hash-size: 4096\n  prealloc: 1000\n  memcap: 32mb\n\n# IP Pair table:\n#\n# Used by xbits \'ippair\' tracking.\n#\n#ippair:\n#  hash-size: 4096\n#  prealloc: 1000\n#  memcap: 32mb\n\n# Decoder settings\n\ndecoder:\n  # Teredo decoder is known to not be completely accurate\n  # it will sometimes detect non-teredo as teredo.\n  teredo:\n    enabled: true\n\n\n##\n## Performance tuning and profiling\n##\n\n# The detection engine builds internal groups of signatures. The engine\n# allow us to specify the profile to use for them, to manage memory on an\n# efficient way keeping a good performance. For the profile keyword you\n# can use the words "low", "medium", "high" or "custom". If you use custom\n# make sure to define the values at "- custom-values" as your convenience.\n# Usually you would prefer medium/high/low.\n#\n# "sgh mpm-context", indicates how the staging should allot mpm contexts for\n# the signature groups.  "single" indicates the use of a single context for\n# all the signature group heads.  "full" indicates a mpm-context for each\n# group head.  "auto" lets the engine decide the distribution of contexts\n# based on the information the engine gathers on the patterns from each\n# group head.\n#\n# The option inspection-recursion-limit is used to limit the recursive calls\n# in the content inspection code.  For certain payload-sig combinations, we\n# might end up taking too much time in the content inspection code.\n# If the argument specified is 0, the engine uses an internally defined\n# default limit.  On not specifying a value, we use no limits on the recursion.\ndetect:\n  profile: medium\n  custom-values:\n    toclient-groups: 3\n    toserver-groups: 25\n  sgh-mpm-context: auto\n  inspection-recursion-limit: 3000\n  # If set to yes, the loading of signatures will be made after the capture\n  # is started. This will limit the downtime in IPS mode.\n  #delayed-detect: yes\n\n  prefilter:\n    # default prefiltering setting. "mpm" only creates MPM/fast_pattern\n    # engines. "auto" also sets up prefilter engines for other keywords.\n    # Use --list-keywords=all to see which keywords support prefiltering.\n    default: mpm\n\n  # the grouping values above control how many groups are created per\n  # direction. Port whitelisting forces that port to get it\'s own group.\n  # Very common ports will benefit, as well as ports with many expensive\n  # rules.\n  grouping:\n    #tcp-whitelist: 53, 80, 139, 443, 445, 1433, 3306, 3389, 6666, 6667, 8080\n    #udp-whitelist: 53, 135, 5060\n\n  profiling:\n    # Log the rules that made it past the prefilter stage, per packet\n    # default is off. The threshold setting determines how many rules\n    # must have made it past pre-filter for that rule to trigger the\n    # logging.\n    #inspect-logging-threshold: 200\n    grouping:\n      dump-to-disk: false\n      include-rules: false      # very verbose\n      include-mpm-stats: false\n\n# Select the multi pattern algorithm you want to run for scan/search the\n# in the engine.\n#\n# The supported algorithms are:\n# "ac"      - Aho-Corasick, default implementation\n# "ac-bs"   - Aho-Corasick, reduced memory implementation\n# "ac-cuda" - Aho-Corasick, CUDA implementation\n# "ac-ks"   - Aho-Corasick, "Ken Steele" variant\n# "hs"      - Hyperscan, available when built with Hyperscan support\n#\n# The default mpm-algo value of "auto" will use "hs" if Hyperscan is\n# available, "ac" otherwise.\n#\n# The mpm you choose also decides the distribution of mpm contexts for\n# signature groups, specified by the conf - "detect.sgh-mpm-context".\n# Selecting "ac" as the mpm would require "detect.sgh-mpm-context"\n# to be set to "single", because of ac\'s memory requirements, unless the\n# ruleset is small enough to fit in one\'s memory, in which case one can\n# use "full" with "ac".  Rest of the mpms can be run in "full" mode.\n#\n# There is also a CUDA pattern matcher (only available if Suricata was\n# compiled with --enable-cuda: b2g_cuda. Make sure to update your\n# max-pending-packets setting above as well if you use b2g_cuda.\n\nmpm-algo: auto\n\n# Select the matching algorithm you want to use for single-pattern searches.\n#\n# Supported algorithms are "bm" (Boyer-Moore) and "hs" (Hyperscan, only\n# available if Suricata has been built with Hyperscan support).\n#\n# The default of "auto" will use "hs" if available, otherwise "bm".\n\nspm-algo: auto\n\n# Suricata is multi-threaded. Here the threading can be influenced.\nthreading:\n  set-cpu-affinity: no\n  # Tune cpu affinity of threads. Each family of threads can be bound\n  # on specific CPUs.\n  #\n  # These 2 apply to the all runmodes:\n  # management-cpu-set is used for flow timeout handling, counters\n  # worker-cpu-set is used for \'worker\' threads\n  #\n  # Additionally, for autofp these apply:\n  # receive-cpu-set is used for capture threads\n  # verdict-cpu-set is used for IPS verdict threads\n  #\n  cpu-affinity:\n    - management-cpu-set:\n        cpu: [ 0 ]  # include only these cpus in affinity settings\n    - receive-cpu-set:\n        cpu: [ 0 ]  # include only these cpus in affinity settings\n    - worker-cpu-set:\n        cpu: [ "all" ]\n        mode: "exclusive"\n        # Use explicitely 3 threads and don\'t compute number by using\n        # detect-thread-ratio variable:\n        # threads: 3\n        prio:\n          low: [ 0 ]\n          medium: [ "1-2" ]\n          high: [ 3 ]\n          default: "medium"\n    #- verdict-cpu-set:\n    #    cpu: [ 0 ]\n    #    prio:\n    #      default: "high"\n  #\n  # By default Suricata creates one "detect" thread per available CPU/CPU core.\n  # This setting allows controlling this behaviour. A ratio setting of 2 will\n  # create 2 detect threads for each CPU/CPU core. So for a dual core CPU this\n  # will result in 4 detect threads. If values below 1 are used, less threads\n  # are created. So on a dual core CPU a setting of 0.5 results in 1 detect\n  # thread being created. Regardless of the setting at a minimum 1 detect\n  # thread will always be created.\n  #\n  detect-thread-ratio: 1.0\n\n# Luajit has a strange memory requirement, it\'s \'states\' need to be in the\n# first 2G of the process\' memory.\n#\n# \'luajit.states\' is used to control how many states are preallocated.\n# State use: per detect script: 1 per detect thread. Per output script: 1 per\n# script.\nluajit:\n  states: 128\n\n# Profiling settings. Only effective if Suricata has been built with the\n# the --enable-profiling configure flag.\n#\nprofiling:\n  # Run profiling for every xth packet. The default is 1, which means we\n  # profile every packet. If set to 1000, one packet is profiled for every\n  # 1000 received.\n  #sample-rate: 1000\n\n  # rule profiling\n  rules:\n\n    # Profiling can be disabled here, but it will still have a\n    # performance impact if compiled in.\n    enabled: yes\n    filename: rule_perf.log\n    append: yes\n\n    # Sort options: ticks, avgticks, checks, matches, maxticks\n    # If commented out all the sort options will be used.\n    #sort: avgticks\n\n    # Limit the number of sids for which stats are shown at exit (per sort).\n    limit: 10\n\n    # output to json\n    json: no\n\n  # per keyword profiling\n  keywords:\n    enabled: yes\n    filename: keyword_perf.log\n    append: yes\n\n  # per rulegroup profiling\n  rulegroups:\n    enabled: yes\n    filename: rule_group_perf.log\n    append: yes\n\n  # packet profiling\n  packets:\n\n    # Profiling can be disabled here, but it will still have a\n    # performance impact if compiled in.\n    enabled: yes\n    filename: packet_stats.log\n    append: yes\n\n    # per packet csv output\n    csv:\n\n      # Output can be disabled here, but it will still have a\n      # performance impact if compiled in.\n      enabled: no\n      filename: packet_stats.csv\n\n  # profiling of locking. Only available when Suricata was built with\n  # --enable-profiling-locks.\n  locks:\n    enabled: no\n    filename: lock_stats.log\n    append: yes\n\n  pcap-log:\n    enabled: no\n    filename: pcaplog_stats.log\n    append: yes\n\n##\n## Netfilter integration\n##\n\n# When running in NFQ inline mode, it is possible to use a simulated\n# non-terminal NFQUEUE verdict.\n# This permit to do send all needed packet to suricata via this a rule:\n#        iptables -I FORWARD -m mark ! --mark $MARK/$MASK -j NFQUEUE\n# And below, you can have your standard filtering ruleset. To activate\n# this mode, you need to set mode to \'repeat\'\n# If you want packet to be sent to another queue after an ACCEPT decision\n# set mode to \'route\' and set next-queue value.\n# On linux >= 3.1, you can set batchcount to a value > 1 to improve performance\n# by processing several packets before sending a verdict (worker runmode only).\n# On linux >= 3.6, you can set the fail-open option to yes to have the kernel\n# accept the packet if suricata is not able to keep pace.\n# bypass mark and mask can be used to implement NFQ bypass. If bypass mark is\n# set then the NFQ bypass is activated. Suricata will set the bypass mark/mask\n# on packet of a flow that need to be bypassed. The Nefilter ruleset has to\n# directly accept all packets of a flow once a packet has been marked.\nnfq:\n#  mode: accept\n#  repeat-mark: 1\n#  repeat-mask: 1\n#  bypass-mark: 1\n#  bypass-mask: 1\n#  route-queue: 2\n#  batchcount: 20\n#  fail-open: yes\n\n#nflog support\nnflog:\n    # netlink multicast group\n    # (the same as the iptables --nflog-group param)\n    # Group 0 is used by the kernel, so you can\'t use it\n  - group: 2\n    # netlink buffer size\n    buffer-size: 18432\n    # put default value here\n  - group: default\n    # set number of packet to queue inside kernel\n    qthreshold: 1\n    # set the delay before flushing packet in the queue inside kernel\n    qtimeout: 100\n    # netlink max buffer size\n    max-size: 20000\n\n##\n## Advanced Capture Options\n##\n\n# general settings affecting packet capture\ncapture:\n  # disable NIC offloading. It\'s restored when Suricata exists.\n  # Enabled by default\n  #disable-offloading: false\n  #\n  # disable checksum validation. Same as setting \'-k none\' on the\n  # commandline\n  #checksum-validation: none\n\n# Netmap support\n#\n# Netmap operates with NIC directly in driver, so you need FreeBSD wich have\n# built-in netmap support or compile and install netmap module and appropriate\n# NIC driver on your Linux system.\n# To reach maximum throughput disable all receive-, segmentation-,\n# checksum- offloadings on NIC.\n# Disabling Tx checksum offloading is *required* for connecting OS endpoint\n# with NIC endpoint.\n# You can find more information at https://github.com/luigirizzo/netmap\n#\nnetmap:\n   # To specify OS endpoint add plus sign at the end (e.g. "eth0+")\n - interface: eth2\n   # Number of receive threads. "auto" uses number of RSS queues on interface.\n   #threads: auto\n   # You can use the following variables to activate netmap tap or IPS mode.\n   # If copy-mode is set to ips or tap, the traffic coming to the current\n   # interface will be copied to the copy-iface interface. If \'tap\' is set, the\n   # copy is complete. If \'ips\' is set, the packet matching a \'drop\' action\n   # will not be copied.\n   # To specify the OS as the copy-iface (so the OS can route packets, or forward\n   # to a service running on the same machine) add a plus sign at the end\n   # (e.g. "copy-iface: eth0+"). Don\'t forget to set up a symmetrical eth0+ -> eth0\n   # for return packets. Hardware checksumming must be *off* on the interface if\n   # using an OS endpoint (e.g. \'ifconfig eth0 -rxcsum -txcsum -rxcsum6 -txcsum6\' for FreeBSD\n   # or \'ethtool -K eth0 tx off rx off\' for Linux).\n   #copy-mode: tap\n   #copy-iface: eth3\n   # Set to yes to disable promiscuous mode\n   # disable-promisc: no\n   # Choose checksum verification mode for the interface. At the moment\n   # of the capture, some packets may be with an invalid checksum due to\n   # offloading to the network card of the checksum computation.\n   # Possible values are:\n   #  - yes: checksum validation is forced\n   #  - no: checksum validation is disabled\n   #  - auto: suricata uses a statistical approach to detect when\n   #  checksum off-loading is used.\n   # Warning: \'checksum-validation\' must be set to yes to have any validation\n   #checksum-checks: auto\n   # BPF filter to apply to this interface. The pcap filter syntax apply here.\n   #bpf-filter: port 80 or udp\n #- interface: eth3\n   #threads: auto\n   #copy-mode: tap\n   #copy-iface: eth2\n   # Put default values here\n - interface: default\n\n# PF_RING configuration. for use with native PF_RING support\n# for more info see http://www.ntop.org/products/pf_ring/\npfring:\n  - interface: eth0\n    # Number of receive threads (>1 will enable experimental flow pinned\n    # runmode)\n    threads: 1\n\n    # Default clusterid.  PF_RING will load balance packets based on flow.\n    # All threads/processes that will participate need to have the same\n    # clusterid.\n    cluster-id: 99\n\n    # Default PF_RING cluster type. PF_RING can load balance per flow.\n    # Possible values are cluster_flow or cluster_round_robin.\n    cluster-type: cluster_flow\n    # bpf filter for this interface\n    #bpf-filter: tcp\n    # Choose checksum verification mode for the interface. At the moment\n    # of the capture, some packets may be with an invalid checksum due to\n    # offloading to the network card of the checksum computation.\n    # Possible values are:\n    #  - rxonly: only compute checksum for packets received by network card.\n    #  - yes: checksum validation is forced\n    #  - no: checksum validation is disabled\n    #  - auto: suricata uses a statistical approach to detect when\n    #  checksum off-loading is used. (default)\n    # Warning: \'checksum-validation\' must be set to yes to have any validation\n    #checksum-checks: auto\n  # Second interface\n  #- interface: eth1\n  #  threads: 3\n  #  cluster-id: 93\n  #  cluster-type: cluster_flow\n  # Put default values here\n  - interface: default\n    #threads: 2\n\n# For FreeBSD ipfw(8) divert(4) support.\n# Please make sure you have ipfw_load="YES" and ipdivert_load="YES"\n# in /etc/loader.conf or kldload\'ing the appropriate kernel modules.\n# Additionally, you need to have an ipfw rule for the engine to see\n# the packets from ipfw.  For Example:\n#\n#   ipfw add 100 divert 8000 ip from any to any\n#\n# The 8000 above should be the same number you passed on the command\n# line, i.e. -d 8000\n#\nipfw:\n\n  # Reinject packets at the specified ipfw rule number.  This config\n  # option is the ipfw rule number AT WHICH rule processing continues\n  # in the ipfw processing system after the engine has finished\n  # inspecting the packet for acceptance.  If no rule number is specified,\n  # accepted packets are reinjected at the divert rule which they entered\n  # and IPFW rule processing continues.  No check is done to verify\n  # this will rule makes sense so care must be taken to avoid loops in ipfw.\n  #\n  ## The following example tells the engine to reinject packets\n  # back into the ipfw firewall AT rule number 5500:\n  #\n  # ipfw-reinjection-rule-number: 5500\n\n\nnapatech:\n    # The Host Buffer Allowance for all streams\n    # (-1 = OFF, 1 - 100 = percentage of the host buffer that can be held back)\n    hba: -1\n\n    # use_all_streams set to "yes" will query the Napatech service for all configured\n    # streams and listen on all of them. When set to "no" the streams config array\n    # will be used.\n    use-all-streams: yes\n\n    # The streams to listen on\n    streams: [1, 2, 3]\n\n# Tilera mpipe configuration. for use on Tilera TILE-Gx.\nmpipe:\n\n  # Load balancing modes: "static", "dynamic", "sticky", or "round-robin".\n  load-balance: dynamic\n\n  # Number of Packets in each ingress packet queue. Must be 128, 512, 2028 or 65536\n  iqueue-packets: 2048\n\n  # List of interfaces we will listen on.\n  inputs:\n  - interface: xgbe2\n  - interface: xgbe3\n  - interface: xgbe4\n\n\n  # Relative weight of memory for packets of each mPipe buffer size.\n  stack:\n    size128: 0\n    size256: 9\n    size512: 0\n    size1024: 0\n    size1664: 7\n    size4096: 0\n    size10386: 0\n    size16384: 0\n\n##\n## Hardware accelaration\n##\n\n# Cuda configuration.\ncuda:\n  # The "mpm" profile.  On not specifying any of these parameters, the engine\'s\n  # internal default values are used, which are same as the ones specified in\n  # in the default conf file.\n  mpm:\n    # The minimum length required to buffer data to the gpu.\n    # Anything below this is MPM\'ed on the CPU.\n    # Can be specified in kb, mb, gb.  Just a number indicates it\'s in bytes.\n    # A value of 0 indicates there\'s no limit.\n    data-buffer-size-min-limit: 0\n    # The maximum length for data that we would buffer to the gpu.\n    # Anything over this is MPM\'ed on the CPU.\n    # Can be specified in kb, mb, gb.  Just a number indicates it\'s in bytes.\n    data-buffer-size-max-limit: 1500\n    # The ring buffer size used by the CudaBuffer API to buffer data.\n    cudabuffer-buffer-size: 500mb\n    # The max chunk size that can be sent to the gpu in a single go.\n    gpu-transfer-size: 50mb\n    # The timeout limit for batching of packets in microseconds.\n    batching-timeout: 2000\n    # The device to use for the mpm.  Currently we don\'t support load balancing\n    # on multiple gpus.  In case you have multiple devices on your system, you\n    # can specify the device to use, using this conf.  By default we hold 0, to\n    # specify the first device cuda sees.  To find out device-id associated with\n    # the card(s) on the system run "suricata --list-cuda-cards".\n    device-id: 0\n    # No of Cuda streams used for asynchronous processing. All values > 0 are valid.\n    # For this option you need a device with Compute Capability > 1.0.\n    cuda-streams: 2\n\n##\n## Include other configs\n##\n\n# Includes.  Files included here will be handled as if they were\n# inlined in this configuration file.\n#include: include1.yaml\n#include: include2.yaml\n')),
                ('conf_HOME_NET', models.CharField(default='[192.168.0.0/24]', max_length=100)),
                ('conf_EXTERNAL_NET', models.CharField(default='!$HOME_NET', max_length=100)),
                ('conf_HTTP_SERVERS', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_SMTP_SERVERS', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_SQL_SERVERS', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_DNS_SERVERS', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_TELNET_SERVERS', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_AIM_SERVERS', models.CharField(default='$EXTERNAL_NET', max_length=100)),
                ('conf_DNP3_SERVER', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_DNP3_CLIENT', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_MODBUS_CLIENT', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_MODBUS_SERVER', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_ENIP_CLIENT', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_ENIP_SERVER', models.CharField(default='$HOME_NET', max_length=100)),
                ('conf_HTTP_PORTS', models.CharField(default='80', max_length=100)),
                ('conf_SHELLCODE_PORTS', models.CharField(default='!80', max_length=100)),
                ('conf_ORACLE_PORTS', models.CharField(default='1521', max_length=100)),
                ('conf_SSH_PORTS', models.CharField(default='22', max_length=100)),
                ('conf_DNP3_PORTS', models.CharField(default='20000', max_length=100)),
                ('conf_MODBUS_PORTS', models.CharField(default='502', max_length=100)),
                ('conf_afpacket_interface', models.CharField(default='eth0', max_length=100)),
                ('conf_applayer_dcerpc', models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_dcerpc', to='suricata.AppLayerType')),
                ('conf_applayer_dns', models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_dns', to='suricata.AppLayerType')),
                ('conf_applayer_ftp', models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_ftp', to='suricata.AppLayerType')),
                ('conf_applayer_http', models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_http', to='suricata.AppLayerType')),
                ('conf_applayer_imap', models.ForeignKey(default=2, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_imap', to='suricata.AppLayerType')),
                ('conf_applayer_msn', models.ForeignKey(default=2, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_msn', to='suricata.AppLayerType')),
                ('conf_applayer_smb', models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_smb', to='suricata.AppLayerType')),
                ('conf_applayer_smtp', models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_smtp', to='suricata.AppLayerType')),
                ('conf_applayer_ssh', models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_ssh', to='suricata.AppLayerType')),
                ('conf_applayer_tls', models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_applayer_tls', to='suricata.AppLayerType')),
            ],
            bases=('home.probeconfiguration',),
        ),
        migrations.CreateModel(
            name='PcapTestSuricata',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('pcap_success', models.FileField(blank=True, upload_to='tmp/pcap/')),
            ],
        ),
        migrations.CreateModel(
            name='RuleSetSuricata',
            fields=[
                ('ruleset_ptr', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.CASCADE, parent_link=True, primary_key=True, serialize=False, to='rules.RuleSet')),
            ],
            bases=('rules.ruleset',),
        ),
        migrations.CreateModel(
            name='ScriptSuricata',
            fields=[
                ('rule_ptr', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.CASCADE, parent_link=True, primary_key=True, serialize=False, to='rules.Rule')),
                ('name', models.CharField(db_index=True, max_length=100, unique=True)),
            ],
            bases=('rules.rule',),
        ),
        migrations.CreateModel(
            name='SignatureSuricata',
            fields=[
                ('rule_ptr', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.CASCADE, parent_link=True, primary_key=True, serialize=False, to='rules.Rule')),
                ('sid', models.IntegerField(db_index=True, help_text="<a target='_blank' href='http://doc.emergingthreats.net/bin/view/Main/SidAllocation'>help</a>", unique=True)),
                ('msg', models.CharField(max_length=1000)),
                ('classtype', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='rules.ClassType')),
            ],
            bases=('rules.rule',),
        ),
        migrations.CreateModel(
            name='SourceSuricata',
            fields=[
                ('source_ptr', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.CASCADE, parent_link=True, primary_key=True, serialize=False, to='rules.Source')),
                ('rulesets', models.ManyToManyField(blank=True, to='suricata.RuleSetSuricata')),
            ],
            bases=('rules.source',),
        ),
        migrations.CreateModel(
            name='Suricata',
            fields=[
                ('probe_ptr', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.CASCADE, parent_link=True, primary_key=True, serialize=False, to='home.Probe')),
                ('configuration', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='suricata.ConfSuricata')),
                ('rulesets', models.ManyToManyField(blank=True, to='suricata.RuleSetSuricata')),
            ],
            bases=('home.probe',),
        ),
        migrations.CreateModel(
            name='ValidationType',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(max_length=100, unique=True)),
            ],
        ),
        migrations.AddField(
            model_name='rulesetsuricata',
            name='scripts',
            field=select2.fields.ManyToManyField(blank=True, help_text=None, sort_value_field_name='sid', to='suricata.ScriptSuricata'),
        ),
        migrations.AddField(
            model_name='rulesetsuricata',
            name='signatures',
            field=select2.fields.ManyToManyField(blank=True, help_text=None, sort_value_field_name='sid', to='suricata.SignatureSuricata'),
        ),
        migrations.AddField(
            model_name='pcaptestsuricata',
            name='probe',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='suricata.Suricata'),
        ),
        migrations.AddField(
            model_name='pcaptestsuricata',
            name='signature',
            field=select2.fields.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='suricata.SignatureSuricata'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_lua',
            field=models.ForeignKey(default=1, on_delete=django.db.models.deletion.CASCADE, related_name='conf_lua', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_alert_dnp3',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_alert_dnp3', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_alert_http',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_alert_http', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_alert_smtp',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_alert_smtp', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_alert_ssh',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_alert_ssh', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_alert_taggedpackets',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_alert_taggedpackets', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_alert_tls',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_alert_tls', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_dns_answer',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_dns_answer', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_dns_query',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_dns_query', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_files_forcemagic',
            field=models.ForeignKey(default=1, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_files_forcemagic', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_http_extended',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_http_extended', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_tls_extended',
            field=models.ForeignKey(default=0, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_tls_extended', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_evelog_xff',
            field=models.ForeignKey(default=1, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_evelog_xff', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_fast',
            field=models.ForeignKey(default=1, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_fast', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_outputs_unified2alert',
            field=models.ForeignKey(default=1, on_delete=django.db.models.deletion.CASCADE, related_name='conf_outputs_unified2alert', to='suricata.ValidationType'),
        ),
        migrations.AddField(
            model_name='confsuricata',
            name='conf_stats',
            field=models.ForeignKey(default=1, on_delete=django.db.models.deletion.CASCADE, related_name='conf_stats', to='suricata.ValidationType'),
        ),
    ]
